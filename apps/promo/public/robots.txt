# Robots.txt for Your SaaS Platform

# Allow all crawlers by default
User-agent: *
Allow: /

# Disallow admin and private areas
Disallow: /admin/
Disallow: /private/
Disallow: /api/
Disallow: /_*

# Allow search engines to crawl CSS and JS files
Allow: /styles/
Allow: /scripts/
Allow: /images/

# Crawl delay for more respectful crawling
Crawl-delay: 1

# Sitemap location
Sitemap: https://example.com/sitemap-index.xml
Sitemap: https://example.com/sitemap-0.xml

# Special rules for specific bots
User-agent: Googlebot
Allow: /

User-agent: Bingbot
Allow: /

User-agent: Slurp
Allow: /

# Block aggressive crawlers
User-agent: SemrushBot
Disallow: /

User-agent: AhrefsBot
Disallow: /

User-agent: MJ12bot
Disallow: /